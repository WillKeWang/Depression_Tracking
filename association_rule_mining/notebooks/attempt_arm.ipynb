{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import timedelta\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "\n",
    "# A minimal data_factory dict with folder paths\n",
    "data_factory = {\n",
    "    \"feature_folder\": {\n",
    "        \"INS-W\": {\n",
    "            1: \"/Users/kwang/Data/globem/INS-W_1/FeatureData/\",\n",
    "            2: \"/Users/kwang/Data/globem/INS-W_2/FeatureData/\",\n",
    "            3: \"/Users/kwang/Data/globem/INS-W_3/FeatureData/\",\n",
    "            4: \"/Users/kwang/Data/globem/INS-W_4/FeatureData/\",\n",
    "        }\n",
    "    },\n",
    "    \"survey_folder\": {\n",
    "        \"INS-W\": {\n",
    "            1: \"/Users/kwang/Data/globem/INS-W_1/SurveyData/\",\n",
    "            2: \"/Users/kwang/Data/globem/INS-W_2/SurveyData/\",\n",
    "            3: \"/Users/kwang/Data/globem/INS-W_3/SurveyData/\",\n",
    "            4: \"/Users/kwang/Data/globem/INS-W_4/SurveyData/\",\n",
    "        }\n",
    "    },\n",
    "    \"participants_info_folder\": {\n",
    "        \"INS-W\": {\n",
    "            1: \"/Users/kwang/Data/globem/INS-W_1/ParticipantsInfoData/\",\n",
    "            2: \"/Users/kwang/Data/globem/INS-W_2/ParticipantsInfoData/\",\n",
    "            3: \"/Users/kwang/Data/globem/INS-W_3/ParticipantsInfoData/\",\n",
    "            4: \"/Users/kwang/Data/globem/INS-W_4/ParticipantsInfoData/\",\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # If only loading dep_weekly or dep_endterm,\n",
    "    # an empty placeholder for threshold_book:\n",
    "    \"threshold_book\": {\n",
    "        # Example of other tasks if expanding beyond dep_weekly / dep_endterm\n",
    "        # \"some_other_survey_task\": {\"threshold_as_true\":10, \"threshold_as_false\":5}\n",
    "    }\n",
    "}\n",
    "def data_loader_read_label_file(institution: str, phase: int, prediction_target: str):\n",
    "    if prediction_target == \"dep_weekly\":\n",
    "        prediction_target_col = \"dep\"  # 'dep' is the column in dep_weekly.csv\n",
    "        csv_path = data_factory[\"survey_folder\"][institution][phase] + \"dep_weekly.csv\"\n",
    "        df_label = pd.read_csv(csv_path)\n",
    "    elif prediction_target == \"dep_endterm\":\n",
    "        prediction_target_col = \"dep\"\n",
    "        csv_path = data_factory[\"survey_folder\"][institution][phase] + \"dep_endterm.csv\"\n",
    "        df_label = pd.read_csv(csv_path)\n",
    "    else:\n",
    "        # For other custom tasks, read from other CSVs or threshold_book:\n",
    "        raise ValueError(f\"Unsupported prediction target: {prediction_target}\")\n",
    "\n",
    "    # Make sure date -> datetime, unify pid format\n",
    "    df_label[\"date\"] = pd.to_datetime(df_label[\"date\"])\n",
    "    df_label[\"pid\"]  = df_label[\"pid\"].apply(lambda x: f\"{x}#{institution}_{phase}\")\n",
    "\n",
    "    # Drop duplicates\n",
    "    df_label = df_label.drop_duplicates([\"pid\", \"date\"], keep=\"last\")\n",
    "\n",
    "    return df_label, prediction_target_col\n",
    "\n",
    "\n",
    "def data_loader_single_dataset_label_based(\n",
    "    institution: str,\n",
    "    phase: int,\n",
    "    prediction_target: str,\n",
    "    flag_more_feat_types: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads the 4-week window of daily features (from rapids.csv) up to each label date,\n",
    "    returning a DataFrame with columns [pid, date, X_raw, y_raw, device_type].\n",
    "    \"\"\"\n",
    "    # --- 1) Read rapids.csv as features ---\n",
    "    df_full_rawdata = pd.read_csv(\n",
    "        data_factory[\"feature_folder\"][institution][phase] + \"rapids.csv\",\n",
    "        low_memory=False\n",
    "    )\n",
    "    df_full_rawdata[\"date\"] = pd.to_datetime(df_full_rawdata[\"date\"])\n",
    "    # unify the pid format\n",
    "    df_full_rawdata[\"pid\"] = df_full_rawdata[\"pid\"].apply(lambda x: f\"{x}#{institution}_{phase}\")\n",
    "\n",
    "    # --- 2) Read participant info (platform.csv) for device_type\n",
    "    df_participant_file = pd.read_csv(\n",
    "        data_factory[\"participants_info_folder\"][institution][phase] + \"platform.csv\",\n",
    "        low_memory=False\n",
    "    )\n",
    "    df_participant_file[\"pid\"] = df_participant_file[\"pid\"].apply(lambda x: f\"{x}#{institution}_{phase}\")\n",
    "    df_participant_file = df_participant_file.set_index(\"pid\")\n",
    "\n",
    "    # --- 3) Load label file (dep_weekly or dep_endterm) ---\n",
    "    df_label, prediction_target_col = data_loader_read_label_file(institution, phase, prediction_target)\n",
    "\n",
    "    # --- 4) Decide which sensor columns to keep\n",
    "    # If only the basic four sensor types (location, screen, sleep, steps),\n",
    "    # set flag_more_feat_types=False, otherwise keep Bluetooth/call too.\n",
    "    if not flag_more_feat_types:\n",
    "        sensor_prefixes = ['f_loc', 'f_screen', 'f_slp', 'f_steps']\n",
    "    else:\n",
    "        sensor_prefixes = ['f_loc', 'f_screen', 'f_slp', 'f_steps', 'f_blue', 'f_call']\n",
    "\n",
    "    retained_features = [\"pid\", \"date\"]\n",
    "    for col in df_full_rawdata.columns:\n",
    "        for ft in sensor_prefixes:\n",
    "            if col.startswith(ft):\n",
    "                retained_features.append(col)\n",
    "                break\n",
    "\n",
    "    # --- 5) Build a 4-week window of data for each label date --- ? is this sufficient?\n",
    "    datapoints = []\n",
    "    for _, row in df_label.iterrows():\n",
    "        pid = row[\"pid\"]\n",
    "        date_end = row[\"date\"]\n",
    "        date_start = date_end - timedelta(days=27)  # 4 weeks ~ 28 days\n",
    "\n",
    "        # slice the raw data for that pid, in [date_start, date_end]\n",
    "        df_data_window = df_full_rawdata[df_full_rawdata[\"pid\"] == pid]\n",
    "        df_data_window = df_data_window[\n",
    "            (df_data_window[\"date\"] >= date_start) &\n",
    "            (df_data_window[\"date\"] <= date_end)\n",
    "        ]\n",
    "        if df_data_window.empty:\n",
    "            continue\n",
    "\n",
    "        # to ensure each day is present in X_raw, we do an outer merge with date range\n",
    "        df_placeholder = pd.DataFrame({\"date\": pd.date_range(date_start, date_end)})\n",
    "        df_placeholder[\"pid\"] = pid\n",
    "        df_data_window = pd.merge(\n",
    "            df_placeholder,\n",
    "            df_data_window[retained_features],\n",
    "            on=[\"pid\",\"date\"],\n",
    "            how=\"left\"\n",
    "        )\n",
    "\n",
    "        # assemble the datapoint\n",
    "        datapoint = {\n",
    "            \"pid\": pid,\n",
    "            \"date\": date_end, \n",
    "            \"X_raw\": df_data_window[retained_features],  # 4-week daily rows\n",
    "            \"y_raw\": row[prediction_target_col],         # label (0 or 1)\n",
    "            \"device_type\": df_participant_file.loc[pid][\"platform\"].split(\";\")[0]\n",
    "        }\n",
    "        datapoints.append(datapoint)\n",
    "\n",
    "    df_datapoints = pd.DataFrame(datapoints)\n",
    "\n",
    "    # optional: remove participants with fewer than 2 label points if prediction_target == 'dep_weekly'\n",
    "    if prediction_target == \"dep_weekly\":\n",
    "        pids_few_response = df_datapoints.groupby(\"pid\").size()\n",
    "        pids_few_response = pids_few_response[pids_few_response < 2].index\n",
    "        df_datapoints = df_datapoints[~df_datapoints[\"pid\"].isin(pids_few_response)]\n",
    "\n",
    "    return df_datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2354, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>date</th>\n",
       "      <th>X_raw</th>\n",
       "      <th>y_raw</th>\n",
       "      <th>device_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INS-W_001#INS-W_1</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>pid       date  \\\n",
       "0   INS-W_...</td>\n",
       "      <td>False</td>\n",
       "      <td>android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INS-W_001#INS-W_1</td>\n",
       "      <td>2018-04-08</td>\n",
       "      <td>pid       date  \\\n",
       "0   INS-W_...</td>\n",
       "      <td>False</td>\n",
       "      <td>android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INS-W_001#INS-W_1</td>\n",
       "      <td>2018-04-11</td>\n",
       "      <td>pid       date  \\\n",
       "0   INS-W_...</td>\n",
       "      <td>False</td>\n",
       "      <td>android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INS-W_001#INS-W_1</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>pid       date  \\\n",
       "0   INS-W_...</td>\n",
       "      <td>False</td>\n",
       "      <td>android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INS-W_001#INS-W_1</td>\n",
       "      <td>2018-04-22</td>\n",
       "      <td>pid       date  \\\n",
       "0   INS-W_...</td>\n",
       "      <td>False</td>\n",
       "      <td>android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pid       date  \\\n",
       "0  INS-W_001#INS-W_1 2018-04-04   \n",
       "1  INS-W_001#INS-W_1 2018-04-08   \n",
       "2  INS-W_001#INS-W_1 2018-04-11   \n",
       "3  INS-W_001#INS-W_1 2018-04-18   \n",
       "4  INS-W_001#INS-W_1 2018-04-22   \n",
       "\n",
       "                                               X_raw  y_raw device_type  \n",
       "0                    pid       date  \\\n",
       "0   INS-W_...  False     android  \n",
       "1                    pid       date  \\\n",
       "0   INS-W_...  False     android  \n",
       "2                    pid       date  \\\n",
       "0   INS-W_...  False     android  \n",
       "3                    pid       date  \\\n",
       "0   INS-W_...  False     android  \n",
       "4                    pid       date  \\\n",
       "0   INS-W_...  False     android  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_datapoints = data_loader_single_dataset_label_based(\n",
    "    institution=\"INS-W\",\n",
    "    phase=1,\n",
    "    prediction_target=\"dep_weekly\",\n",
    "    flag_more_feat_types=False    \n",
    ")\n",
    "\n",
    "print(df_datapoints.shape)\n",
    "df_datapoints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def contains_dis(col_name: str) -> bool:\n",
    "    # Split the column name by ':' and '_' using regex.\n",
    "    tokens = re.split(\"[:_]\", col_name)\n",
    "    # Check if any of the tokens is 'dis'\n",
    "    return \"dis\" in tokens\n",
    "\n",
    "sample_X = df_datapoints.iloc[0]['X_raw']\n",
    "for col in sample_X.columns:\n",
    "    if contains_dis(col):\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 3755)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_datapoints[\"X_raw\"].iloc[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1307\n",
       "True     1047\n",
       "Name: y_raw, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_datapoints[\"y_raw\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt ARM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example subject PID: INS-W_001#INS-W_1\n",
      "Label date: 2018-04-04 00:00:00\n",
      "Encoded sensor data (first few rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>date</th>\n",
       "      <th>f_slp:fitbit_sleep_summary_rapids_sumdurationafterwakeupmain:14dhist</th>\n",
       "      <th>f_slp:fitbit_sleep_summary_rapids_sumdurationasleepmain:14dhist</th>\n",
       "      <th>f_slp:fitbit_sleep_summary_rapids_sumdurationawakemain:14dhist</th>\n",
       "      <th>f_slp:fitbit_sleep_summary_rapids_sumdurationtofallasleepmain:14dhist</th>\n",
       "      <th>f_slp:fitbit_sleep_summary_rapids_sumdurationinbedmain:14dhist</th>\n",
       "      <th>f_slp:fitbit_sleep_summary_rapids_avgefficiencymain:14dhist</th>\n",
       "      <th>f_slp:fitbit_sleep_summary_rapids_avgdurationafterwakeupmain:14dhist</th>\n",
       "      <th>f_slp:fitbit_sleep_summary_rapids_avgdurationasleepmain:14dhist</th>\n",
       "      <th>...</th>\n",
       "      <th>f_loc:phone_locations_doryab_timeattop2location_norm:weekend</th>\n",
       "      <th>f_loc:phone_locations_doryab_timeattop3location_norm:weekend</th>\n",
       "      <th>f_loc:phone_locations_doryab_totaldistance_norm:weekend</th>\n",
       "      <th>f_loc:phone_locations_doryab_varspeed_norm:weekend</th>\n",
       "      <th>f_loc:phone_locations_locmap_duration_in_locmap_study_norm:weekend</th>\n",
       "      <th>f_loc:phone_locations_locmap_percent_in_locmap_study_norm:weekend</th>\n",
       "      <th>f_loc:phone_locations_locmap_duration_in_locmap_exercise_norm:weekend</th>\n",
       "      <th>f_loc:phone_locations_locmap_percent_in_locmap_exercise_norm:weekend</th>\n",
       "      <th>f_loc:phone_locations_locmap_duration_in_locmap_greens_norm:weekend</th>\n",
       "      <th>f_loc:phone_locations_locmap_percent_in_locmap_greens_norm:weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INS-W_001#INS-W_1</td>\n",
       "      <td>2018-03-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INS-W_001#INS-W_1</td>\n",
       "      <td>2018-03-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 3755 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pid       date  \\\n",
       "0  INS-W_001#INS-W_1 2018-03-08   \n",
       "1  INS-W_001#INS-W_1 2018-03-09   \n",
       "\n",
       "   f_slp:fitbit_sleep_summary_rapids_sumdurationafterwakeupmain:14dhist  \\\n",
       "0                                                NaN                      \n",
       "1                                                NaN                      \n",
       "\n",
       "   f_slp:fitbit_sleep_summary_rapids_sumdurationasleepmain:14dhist  \\\n",
       "0                                                NaN                 \n",
       "1                                                NaN                 \n",
       "\n",
       "   f_slp:fitbit_sleep_summary_rapids_sumdurationawakemain:14dhist  \\\n",
       "0                                                NaN                \n",
       "1                                                NaN                \n",
       "\n",
       "   f_slp:fitbit_sleep_summary_rapids_sumdurationtofallasleepmain:14dhist  \\\n",
       "0                                                NaN                       \n",
       "1                                                NaN                       \n",
       "\n",
       "   f_slp:fitbit_sleep_summary_rapids_sumdurationinbedmain:14dhist  \\\n",
       "0                                                NaN                \n",
       "1                                                NaN                \n",
       "\n",
       "   f_slp:fitbit_sleep_summary_rapids_avgefficiencymain:14dhist  \\\n",
       "0                                                NaN             \n",
       "1                                                NaN             \n",
       "\n",
       "   f_slp:fitbit_sleep_summary_rapids_avgdurationafterwakeupmain:14dhist  \\\n",
       "0                                                NaN                      \n",
       "1                                                NaN                      \n",
       "\n",
       "   f_slp:fitbit_sleep_summary_rapids_avgdurationasleepmain:14dhist  ...  \\\n",
       "0                                                NaN                ...   \n",
       "1                                                NaN                ...   \n",
       "\n",
       "   f_loc:phone_locations_doryab_timeattop2location_norm:weekend  \\\n",
       "0                                                NaN              \n",
       "1                                                NaN              \n",
       "\n",
       "   f_loc:phone_locations_doryab_timeattop3location_norm:weekend  \\\n",
       "0                                                NaN              \n",
       "1                                                NaN              \n",
       "\n",
       "   f_loc:phone_locations_doryab_totaldistance_norm:weekend  \\\n",
       "0                                                NaN         \n",
       "1                                                NaN         \n",
       "\n",
       "   f_loc:phone_locations_doryab_varspeed_norm:weekend  \\\n",
       "0                                                NaN    \n",
       "1                                                NaN    \n",
       "\n",
       "   f_loc:phone_locations_locmap_duration_in_locmap_study_norm:weekend  \\\n",
       "0                                                NaN                    \n",
       "1                                                NaN                    \n",
       "\n",
       "   f_loc:phone_locations_locmap_percent_in_locmap_study_norm:weekend  \\\n",
       "0                                                NaN                   \n",
       "1                                                NaN                   \n",
       "\n",
       "   f_loc:phone_locations_locmap_duration_in_locmap_exercise_norm:weekend  \\\n",
       "0                                                NaN                       \n",
       "1                                                NaN                       \n",
       "\n",
       "   f_loc:phone_locations_locmap_percent_in_locmap_exercise_norm:weekend  \\\n",
       "0                                                NaN                      \n",
       "1                                                NaN                      \n",
       "\n",
       "   f_loc:phone_locations_locmap_duration_in_locmap_greens_norm:weekend  \\\n",
       "0                                                NaN                     \n",
       "1                                                NaN                     \n",
       "\n",
       "   f_loc:phone_locations_locmap_percent_in_locmap_greens_norm:weekend  \n",
       "0                                                NaN                   \n",
       "1                                                NaN                   \n",
       "\n",
       "[2 rows x 3755 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# For demonstration, select an example subject's data from your loaded dataset.\n",
    "example = df_datapoints.iloc[0]\n",
    "print(\"Example subject PID:\", example[\"pid\"])\n",
    "print(\"Label date:\", example[\"date\"])\n",
    "\n",
    "df_sensor = example[\"X_raw\"]\n",
    "\n",
    "# Function to check if a column name indicates a discretized feature.\n",
    "def is_discretized_column(col_name: str) -> bool:\n",
    "    tokens = re.split(\"[:_]\", col_name)\n",
    "    return \"dis\" in tokens\n",
    "\n",
    "# Robust function to encode a series of discretized values.\n",
    "def robust_encode(series: pd.Series) -> pd.Series:\n",
    "    # Get the unique non-null values.\n",
    "    unique_vals = series.dropna().unique()\n",
    "    # Check if they are a subset of the expected discrete tokens.\n",
    "    valid_tokens = {\"l\", \"m\", \"h\"}\n",
    "    if len(unique_vals) > 0 and all(val in valid_tokens for val in unique_vals):\n",
    "        mapping = {\"l\": 0, \"m\": 1, \"h\": 2}\n",
    "        return series.map(mapping)\n",
    "    else:\n",
    "        # If not, try converting to numeric (in case it already is numeric).\n",
    "        try:\n",
    "            return pd.to_numeric(series)\n",
    "        except Exception as e:\n",
    "            # If conversion fails, return the original series.\n",
    "            return series\n",
    "\n",
    "# Suppose df_sensor is your sensor DataFrame (the X_raw part for one subject).\n",
    "df_encoded = df_sensor.copy()\n",
    "\n",
    "# Identify sensor columns (exclude metadata like \"pid\" and \"date\")\n",
    "sensor_cols = [col for col in df_sensor.columns if col not in [\"pid\", \"date\"]]\n",
    "\n",
    "# Now loop over sensor columns.\n",
    "for col in sensor_cols:\n",
    "    if is_discretized_column(col):\n",
    "        # For columns with \"dis\", apply robust encoding.\n",
    "        df_encoded[col] = robust_encode(df_sensor[col])\n",
    "    else:\n",
    "        # For columns without \"dis\", they might be all NaN or raw values.\n",
    "        # If they are numeric, you can convert them; if they are all NaN, they won't affect ARM.\n",
    "        try:\n",
    "            df_encoded[col] = pd.to_numeric(df_sensor[col])\n",
    "        except:\n",
    "            df_encoded[col] = df_sensor[col]\n",
    "\n",
    "# Now df_encoded should have numeric values for the discretized features.\n",
    "print(\"Encoded sensor data (first few rows):\")\n",
    "display(df_encoded.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 3755)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try ARM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example subject PID: INS-W_001#INS-W_1\n",
      "Label date: 2018-04-04 00:00:00\n",
      "\n",
      "Example numeric sensor data (first few rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>date</th>\n",
       "      <th>f_slp:fitbit_sleep_summary_rapids_sumdurationafterwakeupmain:14dhist</th>\n",
       "      <th>f_slp:fitbit_sleep_summary_rapids_sumdurationasleepmain:14dhist</th>\n",
       "      <th>f_slp:fitbit_sleep_summary_rapids_sumdurationawakemain:14dhist</th>\n",
       "      <th>f_slp:fitbit_sleep_summary_rapids_sumdurationtofallasleepmain:14dhist</th>\n",
       "      <th>f_slp:fitbit_sleep_summary_rapids_sumdurationinbedmain:14dhist</th>\n",
       "      <th>f_slp:fitbit_sleep_summary_rapids_avgefficiencymain:14dhist</th>\n",
       "      <th>f_slp:fitbit_sleep_summary_rapids_avgdurationafterwakeupmain:14dhist</th>\n",
       "      <th>f_slp:fitbit_sleep_summary_rapids_avgdurationasleepmain:14dhist</th>\n",
       "      <th>...</th>\n",
       "      <th>f_loc:phone_locations_doryab_timeattop2location_norm:weekend</th>\n",
       "      <th>f_loc:phone_locations_doryab_timeattop3location_norm:weekend</th>\n",
       "      <th>f_loc:phone_locations_doryab_totaldistance_norm:weekend</th>\n",
       "      <th>f_loc:phone_locations_doryab_varspeed_norm:weekend</th>\n",
       "      <th>f_loc:phone_locations_locmap_duration_in_locmap_study_norm:weekend</th>\n",
       "      <th>f_loc:phone_locations_locmap_percent_in_locmap_study_norm:weekend</th>\n",
       "      <th>f_loc:phone_locations_locmap_duration_in_locmap_exercise_norm:weekend</th>\n",
       "      <th>f_loc:phone_locations_locmap_percent_in_locmap_exercise_norm:weekend</th>\n",
       "      <th>f_loc:phone_locations_locmap_duration_in_locmap_greens_norm:weekend</th>\n",
       "      <th>f_loc:phone_locations_locmap_percent_in_locmap_greens_norm:weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INS-W_001#INS-W_1</td>\n",
       "      <td>2018-03-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INS-W_001#INS-W_1</td>\n",
       "      <td>2018-03-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INS-W_001#INS-W_1</td>\n",
       "      <td>2018-03-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INS-W_001#INS-W_1</td>\n",
       "      <td>2018-03-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INS-W_001#INS-W_1</td>\n",
       "      <td>2018-03-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3755 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pid       date  \\\n",
       "0  INS-W_001#INS-W_1 2018-03-08   \n",
       "1  INS-W_001#INS-W_1 2018-03-09   \n",
       "2  INS-W_001#INS-W_1 2018-03-10   \n",
       "3  INS-W_001#INS-W_1 2018-03-11   \n",
       "4  INS-W_001#INS-W_1 2018-03-12   \n",
       "\n",
       "   f_slp:fitbit_sleep_summary_rapids_sumdurationafterwakeupmain:14dhist  \\\n",
       "0                                                NaN                      \n",
       "1                                                NaN                      \n",
       "2                                                NaN                      \n",
       "3                                                NaN                      \n",
       "4                                                NaN                      \n",
       "\n",
       "   f_slp:fitbit_sleep_summary_rapids_sumdurationasleepmain:14dhist  \\\n",
       "0                                                NaN                 \n",
       "1                                                NaN                 \n",
       "2                                                NaN                 \n",
       "3                                                NaN                 \n",
       "4                                                NaN                 \n",
       "\n",
       "   f_slp:fitbit_sleep_summary_rapids_sumdurationawakemain:14dhist  \\\n",
       "0                                                NaN                \n",
       "1                                                NaN                \n",
       "2                                                NaN                \n",
       "3                                                NaN                \n",
       "4                                                NaN                \n",
       "\n",
       "   f_slp:fitbit_sleep_summary_rapids_sumdurationtofallasleepmain:14dhist  \\\n",
       "0                                                NaN                       \n",
       "1                                                NaN                       \n",
       "2                                                NaN                       \n",
       "3                                                NaN                       \n",
       "4                                                NaN                       \n",
       "\n",
       "   f_slp:fitbit_sleep_summary_rapids_sumdurationinbedmain:14dhist  \\\n",
       "0                                                NaN                \n",
       "1                                                NaN                \n",
       "2                                                NaN                \n",
       "3                                                NaN                \n",
       "4                                                NaN                \n",
       "\n",
       "   f_slp:fitbit_sleep_summary_rapids_avgefficiencymain:14dhist  \\\n",
       "0                                                NaN             \n",
       "1                                                NaN             \n",
       "2                                                NaN             \n",
       "3                                                NaN             \n",
       "4                                                NaN             \n",
       "\n",
       "   f_slp:fitbit_sleep_summary_rapids_avgdurationafterwakeupmain:14dhist  \\\n",
       "0                                                NaN                      \n",
       "1                                                NaN                      \n",
       "2                                                NaN                      \n",
       "3                                                NaN                      \n",
       "4                                                NaN                      \n",
       "\n",
       "   f_slp:fitbit_sleep_summary_rapids_avgdurationasleepmain:14dhist  ...  \\\n",
       "0                                                NaN                ...   \n",
       "1                                                NaN                ...   \n",
       "2                                                NaN                ...   \n",
       "3                                                NaN                ...   \n",
       "4                                                NaN                ...   \n",
       "\n",
       "   f_loc:phone_locations_doryab_timeattop2location_norm:weekend  \\\n",
       "0                                                NaN              \n",
       "1                                                NaN              \n",
       "2                                                NaN              \n",
       "3                                                NaN              \n",
       "4                                                NaN              \n",
       "\n",
       "   f_loc:phone_locations_doryab_timeattop3location_norm:weekend  \\\n",
       "0                                                NaN              \n",
       "1                                                NaN              \n",
       "2                                                NaN              \n",
       "3                                                NaN              \n",
       "4                                                NaN              \n",
       "\n",
       "   f_loc:phone_locations_doryab_totaldistance_norm:weekend  \\\n",
       "0                                                NaN         \n",
       "1                                                NaN         \n",
       "2                                                NaN         \n",
       "3                                                NaN         \n",
       "4                                                NaN         \n",
       "\n",
       "   f_loc:phone_locations_doryab_varspeed_norm:weekend  \\\n",
       "0                                                NaN    \n",
       "1                                                NaN    \n",
       "2                                                NaN    \n",
       "3                                                NaN    \n",
       "4                                                NaN    \n",
       "\n",
       "   f_loc:phone_locations_locmap_duration_in_locmap_study_norm:weekend  \\\n",
       "0                                                NaN                    \n",
       "1                                                NaN                    \n",
       "2                                                NaN                    \n",
       "3                                                NaN                    \n",
       "4                                                NaN                    \n",
       "\n",
       "   f_loc:phone_locations_locmap_percent_in_locmap_study_norm:weekend  \\\n",
       "0                                                NaN                   \n",
       "1                                                NaN                   \n",
       "2                                                NaN                   \n",
       "3                                                NaN                   \n",
       "4                                                NaN                   \n",
       "\n",
       "   f_loc:phone_locations_locmap_duration_in_locmap_exercise_norm:weekend  \\\n",
       "0                                                NaN                       \n",
       "1                                                NaN                       \n",
       "2                                                NaN                       \n",
       "3                                                NaN                       \n",
       "4                                                NaN                       \n",
       "\n",
       "   f_loc:phone_locations_locmap_percent_in_locmap_exercise_norm:weekend  \\\n",
       "0                                                NaN                      \n",
       "1                                                NaN                      \n",
       "2                                                NaN                      \n",
       "3                                                NaN                      \n",
       "4                                                NaN                      \n",
       "\n",
       "   f_loc:phone_locations_locmap_duration_in_locmap_greens_norm:weekend  \\\n",
       "0                                                NaN                     \n",
       "1                                                NaN                     \n",
       "2                                                NaN                     \n",
       "3                                                NaN                     \n",
       "4                                                NaN                     \n",
       "\n",
       "   f_loc:phone_locations_locmap_percent_in_locmap_greens_norm:weekend  \n",
       "0                                                NaN                   \n",
       "1                                                NaN                   \n",
       "2                                                NaN                   \n",
       "3                                                NaN                   \n",
       "4                                                NaN                   \n",
       "\n",
       "[5 rows x 3755 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample transactions (first 5 days):\n",
      "[418, 421, 424, 428, 430, 435, 436, 439, 442, 446, 448, 451, 456, 457, 646, 651, 654, 657, 661, 665, 668, 672, 675, 676, 679, 682, 686, 688, 691, 694, 697, 700, 704, 706, 710, 1669, 1672, 1675, 1679, 1681, 1686, 1687, 1690, 1693, 1697, 1699, 1702, 1707, 1709, 1897, 1902, 1905, 1908, 1912, 1916, 1919, 1923, 1926, 1927, 1930, 1933, 1937, 1939, 1942, 1945, 1948, 1951, 1955, 1957, 1961, 3165, 3168, 3170, 3174, 3177, 3180, 3181, 3184, 3188, 3190, 3193, 3198, 3201, 3204, 3206, 3209, 3213, 4172, 4174, 4177, 4181, 4183, 4187, 4190, 4192, 4195, 4199, 4201, 4205, 4209, 4212, 4219, 4222, 4227, 4228, 4232, 4235, 4238, 4241, 4245, 4247, 4249, 4253, 4255, 4259, 4261, 4265, 4268, 4271, 4401, 4404, 4407, 4410, 4416, 4419, 4421, 4425, 4428, 4431, 4432, 4435, 4439, 4441, 4444, 4449, 4452, 4455, 4457, 4460, 4463, 5666, 5669, 5672, 5675, 5678, 5682, 5684, 5687, 5690, 5692, 5696, 5700, 5702, 5705, 5708, 5710, 5713, 6721, 6724, 6729, 6731, 6735, 6738, 6741, 6744, 6747, 6749, 6752, 6754, 6757, 6760, 6763, 6768, 6770, 6773, 6916, 6919, 6923, 6925, 6928, 6931, 6936, 6938, 6941, 6945, 6946, 6949, 6952, 6955, 6959, 6961, 7973, 7977, 7979, 7982, 7984, 7987, 7990, 7993, 7998, 8001, 8002, 8006, 8010, 8013, 8014, 8018, 8020, 8025, 8169, 8172, 8174, 8178, 8181, 8184, 8185, 8188, 8192, 8194, 8197, 8202, 8205, 8208, 8210, 8214, 8217]\n",
      "[418, 421, 424, 428, 430, 433, 436, 439, 443, 446, 448, 451, 456, 457, 461, 464, 646, 651, 654, 657, 658, 661, 665, 668, 672, 675, 676, 679, 682, 686, 688, 691, 694, 697, 700, 704, 706, 710, 1669, 1672, 1675, 1679, 1681, 1684, 1687, 1690, 1694, 1697, 1699, 1702, 1707, 1709, 1712, 1715, 1897, 1902, 1905, 1908, 1909, 1912, 1916, 1919, 1923, 1926, 1927, 1930, 1933, 1937, 1939, 1942, 1945, 1948, 1951, 1955, 1957, 1961, 3164, 3168, 3170, 3173, 3177, 3179, 3182, 3185, 3188, 3191, 3194, 3197, 3200, 3203, 3206, 3209, 3212, 4172, 4174, 4179, 4181, 4184, 4186, 4190, 4192, 4197, 4199, 4202, 4205, 4209, 4212, 4214, 4217, 4221, 4224, 4225, 4228, 4231, 4234, 4237, 4240, 4244, 4246, 4251, 4253, 4257, 4259, 4263, 4264, 4268, 4270, 4400, 4403, 4406, 4409, 4415, 4418, 4421, 4424, 4428, 4430, 4433, 4435, 4439, 4442, 4444, 4448, 4451, 4454, 4457, 4460, 4463, 5665, 5669, 5672, 5674, 5678, 5680, 5685, 5686, 5690, 5694, 5696, 5698, 5701, 5706, 5708, 5711, 5714, 6722, 6726, 6727, 6731, 6734, 6737, 6740, 6743, 6745, 6749, 6752, 6756, 6759, 6761, 6764, 6766, 6770, 6773, 6918, 6921, 6923, 6927, 6930, 6932, 6934, 6939, 6941, 6944, 6948, 6949, 6954, 6957, 6959, 6963, 6966, 7974, 7975, 7978, 7981, 7984, 7987, 7990, 7993, 7996, 7999, 8004, 8006, 8010, 8013, 8016, 8017, 8022, 8023, 8169, 8172, 8174, 8178, 8181, 8184, 8185, 8188, 8192, 8194, 8197, 8202, 8205, 8207, 8210, 8212, 8215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kwang/opt/anaconda3/envs/globem/lib/python3.8/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "RuntimeError: reentrant call inside <_io.BufferedReader name=68>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kwang/opt/anaconda3/envs/globem/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/Users/kwang/opt/anaconda3/envs/globem/lib/python3.8/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kwang/opt/anaconda3/envs/globem/lib/python3.8/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/Users/kwang/opt/anaconda3/envs/globem/lib/python3.8/socket.py\", line 681, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Users/kwang/opt/anaconda3/envs/globem/lib/python3.8/site-packages/pyspark/context.py\", line 377, in signal_handler\n",
      "    self.cancelAllJobs()\n",
      "  File \"/Users/kwang/opt/anaconda3/envs/globem/lib/python3.8/site-packages/pyspark/context.py\", line 2255, in cancelAllJobs\n",
      "    self._jsc.sc().cancelAllJobs()\n",
      "  File \"/Users/kwang/opt/anaconda3/envs/globem/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1322, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/Users/kwang/opt/anaconda3/envs/globem/lib/python3.8/site-packages/pyspark/errors/exceptions/captured.py\", line 169, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/Users/kwang/opt/anaconda3/envs/globem/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o14.sc\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kwang/opt/anaconda3/envs/globem/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/Users/kwang/opt/anaconda3/envs/globem/lib/python3.8/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o72.collectToPython",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 116\u001b[0m\n\u001b[1;32m    113\u001b[0m model \u001b[38;5;241m=\u001b[39m fpGrowth\u001b[38;5;241m.\u001b[39mfit(df_transactions)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Retrieve the association rules as a Pandas DataFrame.\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m rules \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massociationRules\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoPandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAssociation Rules:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mprint\u001b[39m(rules)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/globem/lib/python3.8/site-packages/pyspark/sql/pandas/conversion.py:208\u001b[0m, in \u001b[0;36mPandasConversionMixin.toPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# Below is toPandas without Arrow optimization.\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m pdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m    209\u001b[0m column_counter \u001b[38;5;241m=\u001b[39m Counter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m    211\u001b[0m corrected_dtypes: List[Optional[Type]] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/globem/lib/python3.8/site-packages/pyspark/sql/dataframe.py:1216\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[1;32m   1197\u001b[0m \n\u001b[1;32m   1198\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;124;03m[Row(age=14, name='Tom'), Row(age=23, name='Alice'), Row(age=16, name='Bob')]\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc):\n\u001b[0;32m-> 1216\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/globem/lib/python3.8/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/globem/lib/python3.8/site-packages/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/globem/lib/python3.8/site-packages/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m                 \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m answer[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o72.collectToPython"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "# A simple function to encode a numeric series into \"l\", \"m\", \"h\" based on its 33rd and 66th percentiles.\n",
    "def encode_low_med_high(series):\n",
    "    if series.dropna().empty:\n",
    "        return series\n",
    "    q33, q66 = series.quantile(0.33), series.quantile(0.66)\n",
    "    def mapper(val):\n",
    "        if pd.isna(val):\n",
    "            return np.nan\n",
    "        if val < q33:\n",
    "            return \"l\"\n",
    "        elif val < q66:\n",
    "            return \"m\"\n",
    "        else:\n",
    "            return \"h\"\n",
    "    return series.apply(mapper)\n",
    "\n",
    "# --- STEP 1: Select one subject's data and encode sensor features ---\n",
    "# (Assume df_datapoints is already loaded by your dataloader; here we take the first subject for example)\n",
    "\n",
    "example = df_datapoints.iloc[0]\n",
    "print(\"Example subject PID:\", example[\"pid\"])\n",
    "print(\"Label date:\", example[\"date\"])\n",
    "\n",
    "# Get the sensor data for this subject (the 4-week window)\n",
    "df_sensor = example[\"X_raw\"]\n",
    "\n",
    "# Make a copy for encoding\n",
    "df_encoded = df_sensor.copy()\n",
    "\n",
    "# Identify sensor columns: assume that all columns except \"pid\" and \"date\" are sensor features.\n",
    "sensor_cols = [col for col in df_sensor.columns if col not in [\"pid\", \"date\"]]\n",
    "\n",
    "# (Optional) If your raw sensor features are not yet encoded to \"l\"/\"m\"/\"h\",\n",
    "# you can apply the above function column‐wise.\n",
    "# For example, if the column is numeric you might do:\n",
    "# df_encoded[col] = encode_low_med_high(df_sensor[col])\n",
    "# (In our case, you mentioned the “with dis” columns already contain strings like \"l\".)\n",
    "\n",
    "# --- STEP 2: Create a mapping dictionary for sensor columns ---\n",
    "# We assign unique codes for each sensor column’s levels.\n",
    "mapping_dict = {}\n",
    "counter = 1\n",
    "for col in sensor_cols:\n",
    "    # Here, for each sensor column, we assign:\n",
    "    # l -> counter, m -> counter+1, h -> counter+2.\n",
    "    mapping_dict[col] = {\"l\": counter, \"m\": counter + 1, \"h\": counter + 2}\n",
    "    counter += 3\n",
    "\n",
    "# Now, create a numeric version of the sensor data.\n",
    "df_numeric = df_encoded.copy()\n",
    "\n",
    "# Process only sensor columns (skip meta columns)\n",
    "for col in sensor_cols:\n",
    "    # We assume the column contains either NaN or one of \"l\", \"m\", \"h\".\n",
    "    # (If you ever get numeric values already, you might want to leave them untouched.)\n",
    "    def map_val(val):\n",
    "        if pd.isna(val):\n",
    "            return np.nan\n",
    "        # If the value is already numeric (unlikely in a \"dis\" column), return as is.\n",
    "        try:\n",
    "            # This conversion is only attempted for sensor levels.\n",
    "            return mapping_dict[col][str(val).lower()]\n",
    "        except KeyError:\n",
    "            # In case the value is not one of \"l\", \"m\", \"h\" (e.g. a PID), return NaN.\n",
    "            return np.nan\n",
    "    df_numeric[col] = df_numeric[col].apply(map_val)\n",
    "\n",
    "print(\"\\nExample numeric sensor data (first few rows):\")\n",
    "display(df_numeric.head())\n",
    "\n",
    "# --- STEP 3: Create transactions for ARM ---\n",
    "# Here, we assume each row in df_numeric corresponds to one day.\n",
    "# We convert each row (across the sensor_cols) into a list of item codes.\n",
    "transactions = (\n",
    "    df_numeric[sensor_cols]\n",
    "    .dropna(how=\"all\")  # drop days with all missing sensor data\n",
    "    .apply(lambda row: [int(row[col]) for col in sensor_cols if pd.notna(row[col])], axis=1)\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "print(\"Sample transactions (first 5 days):\")\n",
    "for t in transactions[:5]:\n",
    "    print(t)\n",
    "\n",
    "# --- STEP 4: Run Association Rule Mining (ARM) using Spark's FPGrowth ---\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "\n",
    "# Initialize a local SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ARMExample\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Create a Spark DataFrame for transactions.\n",
    "# Here, we give each transaction an ID.\n",
    "df_transactions = spark.createDataFrame(\n",
    "    [(i, t) for i, t in enumerate(transactions) if len(t) > 1],  # only transactions with >1 item\n",
    "    [\"id\", \"items\"]\n",
    ")\n",
    "\n",
    "# Set thresholds for FPGrowth (tweak these as needed)\n",
    "min_support = 0.2  # e.g., an itemset appears in at least 20% of days\n",
    "min_confidence = 0.6\n",
    "\n",
    "fpGrowth = FPGrowth(itemsCol=\"items\", minSupport=min_support, minConfidence=min_confidence)\n",
    "model = fpGrowth.fit(df_transactions)\n",
    "\n",
    "# Retrieve the association rules as a Pandas DataFrame.\n",
    "rules = model.associationRules.toPandas()\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules)\n",
    "\n",
    "# Stop Spark when done.\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "globem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
